{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第七课 工作流程与模型优化\n",
    "## 目录\n",
    "\n",
    "* [一、前序工作流程](#1)\n",
    "* [1.1 数据处理](#1.1)\n",
    "* [1.2 特征工程](#1.2)\n",
    "* [1.3 模型选择](#1.3)\n",
    "* [1.4 交叉验证](#1.4)\n",
    "* [1.5 寻找最佳超参数](#1.5)\n",
    "\n",
    "* [二、模型优化](#2)\n",
    "* [2.1 模型状态](#2.1)\n",
    "* [2.2 权重分析](#2.2)\n",
    "* [2.3 bad-case分析](#2.3)\n",
    "* [2.4 模型融合](#2.4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span id=\"1\">一、前序工作流程</span></h3>\n",
    "<h3><span id=\"1.1\">1.1 数据处理</span></h3>\n",
    "1.1.1. 数据清洗<br>\n",
    "　　数据清理需要做的事情就是去掉脏数据，清洗过程中有助于理解业务。\n",
    "　　不可信的样本丢掉：一些样本数据不合符厂里，如身高3米的人<br>\n",
    "　　缺省值多的字段考虑不用，或者用其他方法替换：<br>\n",
    "    \n",
    "1.1.2. 数据采样<br>\n",
    "　　数据采样主要解决正负样本不均衡问题。<br>\n",
    "　　<font color='red'>为什么要进行采样？</font>在实际情况中，样本经常处于不均衡状态，如疾病患者和健康人的数量差别很大。然后大多数模型对正负样本比是敏感的，如LR模型。假如健康人数和得病人数的比例为98:2，则分类器只要把新样本预测为健康，就可得到98%的准确率但是这样的的分类器没有实际价值。<font color='red'>(具体细节？？？)</font><br>\n",
    "　　<font color='red'>如何处理分类不均衡问题？</font>假设正样本少，负样本多的情况下。 （1）当正负样本量均较大时，采用<font color='red'>下采样(欠采样undersampling)</font>：去除一些负样本使得正负样本比例均衡。（2）当两者量不大时，可采取<font color='red'>上采样（过采样oversampling）</font>，即采用一定的方法增加正样本数量，如SMOTE算法。（3）基于原始的数据学习，在用分类器进行预测时，采取<font color='red'>阈值移动（threshold-moving）或者再缩放（rescaling）策略</font>。以二分类LR为例，在样本均衡情况下 \n",
    "  $$h_{\\theta}(x) = g(\\theta^{T}x)$$\n",
    "反映了预测为正例和负例的概率比值。该比值与一个阈值比较，若 \n",
    "$$h_{\\theta}(x) > 0.5$$，\n",
    "则预测为正例。反之为负例。如正样本数为P，负样本数为N，若\n",
    "$$h_{\\theta}(X) > \\frac{P}{N}$$则预测为正例，反之为负例。但是分类器使用的阈值为0.5，因此在预测的时候要进行“阈值移动”，即使用公式：\n",
    "$$ h_{\\theta}(X) \\frac{P}{N} > 0.5 $$ \n",
    "再缩放策略也是<font color='red'>代价敏感学习（cost-sensitive learning）</font>的基础。(详见《机器学习》周志华P67)\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span id='1.2'>1.2 特征工程</span></h3>\n",
    "\n",
    "1.1 特征处理<br>\n",
    "    特征类型：<br>数值型<br>类别型<br>时间型<br>文本型<br>统计型<br>组合特征<br>\n",
    "2. 特征选择  \n",
    "过滤型<br>\n",
    "包裹型<br>\n",
    "嵌入型:基于模型的，selectfrommodel、L1正则化（截断性）<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型选择和评估\n",
    "\n",
    "1. 有数据、有目标，用什么算法：没有万能的模型，只有合适的模型。在特征工程之后选择比较恰当的机器学习算法。<br>[scikit-learn cheat sheet](http://scikit-learn.org/stable/tutorial/machine_learning_map/)  <br>\n",
    "[8个最好的机器学习速查表（Cheat Sheets）](http://www.open-open.com/news/view/609191)<br>\n",
    "\n",
    "2. 有数据、有目标，算法已确定，<font color=red>模型超参数选择</font><br>\n",
    "交叉验证cross validation：K-flod<br>\n",
    "<font color=red>训练集</font>：训练模型<br>\n",
    "<font color=red>验证集</font>：做参数和模型选择，把训练集中的一部分作为验证集，另外一部分作为训练集。<br>\n",
    "<font color=red>测试集</font>：对模型效果评估<br>\n",
    "训练集和验证集组成训练数据<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型参数含义\n",
    "1. 对模型有何影响。有哪些参数，参数的含义是什么？<br>\n",
    "class sklearn.linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='liblinear', max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)\n",
    "2. 交叉验证选取 GridSearchCV<br>\n",
    "class sklearn.grid_search.GridSearchCV(estimator, param_grid, scoring=None, fit_params=None, n_jobs=1, iid=True, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score='raise')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型效果优化\n",
    "### 1. 模型状态<br>\n",
    "  <font color=red>过拟合：高方差<br>\n",
    "  欠拟合：高偏差<br></font>\n",
    "### 2. 如何判断状态   \n",
    "模型状态验证工具：学习曲线（偏差-方差分析）<br>\n",
    "偏差：模型在训练集上的准确率<br>\n",
    "方差：模型在验证集上的准确率<br>\n",
    "横坐标：不同量级的训练样本<br>\n",
    "纵坐标：训练集和验证集上准确率等度量标准<br>\n",
    "曲线大致走势：训练集准确率随着样本量增加逐渐减小，验证集准确率随着数据量增加逐渐增大。<br>\n",
    "在欠拟合的情况下，在训练集和验证集上的准确率均较低，并且随着数据量的增加越来越接近，即存在高偏差<br>\n",
    "在过拟合的情况下，在训练集上的准确率较高，验证集的准确率远低于训练集，曲线存在很大的gap，即存在低偏差、高方差问题。<br>\n",
    "在较好的情况下，在训练集和验证集上的准确率均较高，方差和偏差均差不多，并且处于可接受的范围<br>\n",
    "### 3. 不同模型状态的处理\n",
    "#### 3.1过拟合\n",
    " * 找更多的数据\n",
    " * 增大正则化项的系数，增大惩罚系数\n",
    " * 减少特征的个数(不太推荐)\n",
    "#### 3.2欠拟合\n",
    "#### 3.3 线性模型的权重分析\n",
    "若使用线性或者线性kernel的模型，最终得到一组系数thetas,每一个theta均有实际的物理含义，分析每一个theta对模型的影响，从而决定该维的特征是否可以进一步处理，如平方项，组合特征、统计特征。<br>\n",
    "#### 3.4 bad-case分析\n",
    "哪些训练样本(CV,test)分错了？哪些特征使它分错（差距大）？这些分错的样本是否有共性？是否还有没挖掘的特性？\n",
    "### 4. 模型融合\n",
    "<font color=red>Bagging(融合式)</font>: 每次取一个子集训练（样本子集和特征子集），得到多个模型，根据模型结果进行投票或者平均。<br>\n",
    "解决过拟合问题，使模型的波动减小\n",
    "<br>\n",
    "<font color=red>Boosting(增强式)</font>:重复的训练，并且关注分错类（偏差较大）的样本，分配更高的权重；最简单的分类器加权叠加。（线性模型组合非线性模型）。（常用单层一个节点的树）<br>\n",
    "解决欠拟合问题，可能过拟合<br>\n",
    "分类Adaboost：一个弱学习器加权叠加<br>\n",
    "回归Gradient Boosting Tree：多次进行拟合原始数据得到的（简单）预测器和拟合残差数据得到的（简单）预测器叠加，最终得到一个复杂的预测器。<br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
